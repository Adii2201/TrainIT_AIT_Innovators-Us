{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wmf2lOt3MHfk",
        "outputId": "6030494c-9140-4f9f-dc25-5e2aeb981e1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy pandas matplotlib scikit-learn tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/data.csv', encoding='latin1')  # or ISO-8859-1\n",
        "print(data.columns)  # Show available column names\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bIcAGwsNLzG",
        "outputId": "780c0276-3650-424f-f01a-831e6a28c596"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['stn_code', 'sampling_date', 'state', 'location', 'agency', 'type',\n",
            "       'so2', 'no2', 'rspm', 'spm', 'location_monitoring_station', 'pm2_5',\n",
            "       'date'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-f3e006dc557a>:3: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv('/content/data.csv', encoding='latin1')  # or ISO-8859-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original dataset shape:\", data.shape)\n",
        "data = data.dropna()\n",
        "print(\"After dropping NaN:\", data.shape)  # Should not be (0, X)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3geYWEqtOEsO",
        "outputId": "7079acab-317e-43e6-9665-98b7b6ddfc42"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape: (0, 14)\n",
            "After dropping NaN: (0, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/data.csv', encoding='latin1', low_memory=False)\n",
        "print(data.head())  # Show first 5 rows\n",
        "print(\"Dataset shape:\", data.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFDsHqFtOO6Q",
        "outputId": "63394bdd-af32-4244-a5cd-5c99dee886c7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  stn_code       sampling_date           state   location agency  \\\n",
            "0      150  February - M021990  Andhra Pradesh  Hyderabad    NaN   \n",
            "1      151  February - M021990  Andhra Pradesh  Hyderabad    NaN   \n",
            "2      152  February - M021990  Andhra Pradesh  Hyderabad    NaN   \n",
            "3      150     March - M031990  Andhra Pradesh  Hyderabad    NaN   \n",
            "4      151     March - M031990  Andhra Pradesh  Hyderabad    NaN   \n",
            "\n",
            "                                 type  so2   no2  rspm  spm  \\\n",
            "0  Residential, Rural and other Areas  4.8  17.4   NaN  NaN   \n",
            "1                     Industrial Area  3.1   7.0   NaN  NaN   \n",
            "2  Residential, Rural and other Areas  6.2  28.5   NaN  NaN   \n",
            "3  Residential, Rural and other Areas  6.3  14.7   NaN  NaN   \n",
            "4                     Industrial Area  4.7   7.5   NaN  NaN   \n",
            "\n",
            "  location_monitoring_station  pm2_5        date  \n",
            "0                         NaN    NaN  1990-02-01  \n",
            "1                         NaN    NaN  1990-02-01  \n",
            "2                         NaN    NaN  1990-02-01  \n",
            "3                         NaN    NaN  1990-03-01  \n",
            "4                         NaN    NaN  1990-03-01  \n",
            "Dataset shape: (435742, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load dataset with correct encoding\n",
        "data = pd.read_csv('/content/data.csv', encoding='latin1', low_memory=False)\n",
        "\n",
        "# Convert numeric columns safely\n",
        "num_cols = ['so2', 'no2', 'rspm', 'spm', 'pm2_5']\n",
        "for col in num_cols:\n",
        "    data[col] = pd.to_numeric(data[col], errors='coerce')  # Convert to numbers\n",
        "\n",
        "# Fill missing values using the median of each column\n",
        "for col in num_cols:\n",
        "    data[col] = data[col].fillna(data[col].median())\n",
        "\n",
        "# Define anomaly labels (Top 5% of PM2.5 as anomalies)\n",
        "threshold = data['pm2_5'].quantile(0.95)\n",
        "data['target'] = (data['pm2_5'] > threshold).astype(int)\n",
        "\n",
        "# Select Features (Dropping non-relevant columns)\n",
        "X = data[num_cols]  # Only numeric features\n",
        "y = data['target']\n",
        "\n",
        "# Normalize data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Confirm shape\n",
        "print(f\"Train set: {X_train.shape}, Test set: {X_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Efu6lfYMenn",
        "outputId": "b738cdc6-9907-4f29-f674-a7d0196c8b7a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: (348593, 5), Test set: (87149, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define Autoencoder Model\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(X_train.shape[1],)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),  # Bottleneck (compressed representation)\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(X_train.shape[1], activation='sigmoid')  # Output same shape as input\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model (unsupervised training)\n",
        "history = model.fit(X_train, X_train, epochs=50, batch_size=32, validation_data=(X_test, X_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7hQgBNmOfx1",
        "outputId": "539bb821-cd6b-458b-d5a9-2d46e826b0d5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3ms/step - loss: 0.6518 - val_loss: 0.7176\n",
            "Epoch 2/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 0.6722 - val_loss: 0.7172\n",
            "Epoch 3/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 0.6794 - val_loss: 0.7172\n",
            "Epoch 4/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 0.6892 - val_loss: 0.7172\n",
            "Epoch 5/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 0.6778 - val_loss: 0.7173\n",
            "Epoch 6/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 0.6752 - val_loss: 0.7172\n",
            "Epoch 7/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 0.6563 - val_loss: 0.7171\n",
            "Epoch 8/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 0.6494 - val_loss: 0.7171\n",
            "Epoch 9/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 0.6708 - val_loss: 0.7171\n",
            "Epoch 10/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - loss: 0.6602 - val_loss: 0.7171\n",
            "Epoch 11/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - loss: 0.6632 - val_loss: 0.7171\n",
            "Epoch 12/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3ms/step - loss: 0.6815 - val_loss: 0.7171\n",
            "Epoch 13/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.6735 - val_loss: 0.7171\n",
            "Epoch 14/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - loss: 0.6706 - val_loss: 0.7171\n",
            "Epoch 15/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - loss: 0.6863 - val_loss: 0.7172\n",
            "Epoch 16/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.6817 - val_loss: 0.7171\n",
            "Epoch 17/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 0.6792 - val_loss: 0.7171\n",
            "Epoch 18/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 0.6748 - val_loss: 0.7171\n",
            "Epoch 19/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - loss: 0.6640 - val_loss: 0.7171\n",
            "Epoch 20/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 0.6556 - val_loss: 0.7171\n",
            "Epoch 21/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.6544 - val_loss: 0.7171\n",
            "Epoch 22/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 0.6539 - val_loss: 0.7171\n",
            "Epoch 23/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 0.6624 - val_loss: 0.7171\n",
            "Epoch 24/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.6623 - val_loss: 0.7171\n",
            "Epoch 25/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 0.6363 - val_loss: 0.7171\n",
            "Epoch 26/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 0.6701 - val_loss: 0.7171\n",
            "Epoch 27/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - loss: 0.6522 - val_loss: 0.7171\n",
            "Epoch 28/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 0.6420 - val_loss: 0.7171\n",
            "Epoch 29/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - loss: 0.6534 - val_loss: 0.7171\n",
            "Epoch 30/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 0.6663 - val_loss: 0.7171\n",
            "Epoch 31/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - loss: 0.6547 - val_loss: 0.7171\n",
            "Epoch 32/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3ms/step - loss: 0.6675 - val_loss: 0.7171\n",
            "Epoch 33/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - loss: 0.6404 - val_loss: 0.7171\n",
            "Epoch 34/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 0.6548 - val_loss: 0.7171\n",
            "Epoch 35/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - loss: 0.6787 - val_loss: 0.7171\n",
            "Epoch 36/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - loss: 0.6635 - val_loss: 0.7171\n",
            "Epoch 37/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - loss: 0.6741 - val_loss: 0.7171\n",
            "Epoch 38/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - loss: 0.6372 - val_loss: 0.7171\n",
            "Epoch 39/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 0.6684 - val_loss: 0.7171\n",
            "Epoch 40/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 0.6651 - val_loss: 0.7171\n",
            "Epoch 41/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3ms/step - loss: 0.6785 - val_loss: 0.7171\n",
            "Epoch 42/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3ms/step - loss: 0.6650 - val_loss: 0.7171\n",
            "Epoch 43/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 0.6400 - val_loss: 0.6920\n",
            "Epoch 44/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3ms/step - loss: 0.6411 - val_loss: 0.6919\n",
            "Epoch 45/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 0.6360 - val_loss: 0.6919\n",
            "Epoch 46/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 0.6236 - val_loss: 0.6919\n",
            "Epoch 47/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 0.6393 - val_loss: 0.6919\n",
            "Epoch 48/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 0.6532 - val_loss: 0.6919\n",
            "Epoch 49/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 0.6439 - val_loss: 0.6919\n",
            "Epoch 50/50\n",
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - loss: 0.6438 - val_loss: 0.6919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Predict reconstruction error\n",
        "train_pred = model.predict(X_train)\n",
        "train_mse = np.mean(np.power(X_train - train_pred, 2), axis=1)\n",
        "\n",
        "test_pred = model.predict(X_test)\n",
        "test_mse = np.mean(np.power(X_test - test_pred, 2), axis=1)\n",
        "\n",
        "# Set anomaly detection threshold (95th percentile)\n",
        "threshold = np.percentile(train_mse, 95)\n",
        "\n",
        "# Classify anomalies\n",
        "y_test_pred = (test_mse > threshold).astype(int)\n",
        "\n",
        "# Evaluate model\n",
        "accuracy = accuracy_score(y_test, y_test_pred)\n",
        "precision = precision_score(y_test, y_test_pred)\n",
        "recall = recall_score(y_test, y_test_pred)\n",
        "f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Model Performance:\\nAccuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1-score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSn7qPtBXbfq",
        "outputId": "24ae643e-48ad-4811-a38b-c49776a013a2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10894/10894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step\n",
            "\u001b[1m2724/2724\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
            "Model Performance:\n",
            "Accuracy: 0.9483757702325901\n",
            "Precision: 0.09948580371115583\n",
            "Recall: 0.48580786026200873\n",
            "F1-score: 0.16515123399517537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "import keras.saving\n",
        "keras.saving.save_model(model, 'anomaly_model.keras')\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "\n",
        "# Generate performance report\n",
        "report = f\"\"\"\n",
        "Anomaly Detection Model Performance:\n",
        "------------------------------------\n",
        "Accuracy: {accuracy}\n",
        "Precision: {precision}\n",
        "Recall: {recall}\n",
        "F1-score: {f1}\n",
        "\"\"\"\n",
        "\n",
        "with open(\"report.txt\", \"w\") as file:\n",
        "    file.write(report)\n",
        "\n",
        "print(\"✅ Model saved & report generated!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtlQxE3cX5W3",
        "outputId": "0372ccd0-ee60-4c21-fab7-5558680776df"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model saved & report generated!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Load the saved model\n",
        "model = keras.models.load_model('anomaly_model.keras')\n",
        "\n",
        "# Use it for predictions\n",
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZjpiafBYNhB",
        "outputId": "935618bc-34db-44c0-ebe9-818fc1c25b67"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m  46/2724\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step   "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 14 variables whereas the saved optimizer has 26 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2724/2724\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# List of files to download\n",
        "files_to_download = ['anomaly_model.keras', 'scaler.pkl', 'report.txt']\n",
        "\n",
        "# Download each file\n",
        "for file in files_to_download:\n",
        "    files.download(file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Dk6ASYUTYTzz",
        "outputId": "81f37748-cad0-4f3e-831b-241b7af76dd7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ba074eb1-b105-4a2d-9e95-c88883e39d70\", \"anomaly_model.keras\", 306025)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_daee6840-b46d-4ee4-b2cb-d34ce1f9f6e8\", \"scaler.pkl\", 1071)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a1783e29-b789-4c7c-8c99-cbdb979ef78e\", \"report.txt\", 193)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load your trained model\n",
        "model = tf.keras.models.load_model('anomaly_model.keras')\n",
        "\n",
        "# Convert the model to TensorFlow Lite format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the .tflite model\n",
        "with open(\"anomaly_model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"✅ Model converted to TensorFlow Lite format.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcE1rWq0Z84g",
        "outputId": "81035d49-2dfb-4dd3-cd13-b375f19a7931"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpcamfc651'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 5), dtype=tf.float32, name='input_layer')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  135868139345040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135868139351952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135868139347728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135868139350224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135868181811792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135868181811024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135868181810256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135868181807376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135868181812368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135868181810448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135868181809872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135868181810064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "✅ Model converted to TensorFlow Lite format.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('anomaly_model.tflite')  # Download the TensorFlow Lite model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "izWCvDMpbR5Y",
        "outputId": "d43bf3ad-64f1-4549-816c-7ee150854885"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_97466fba-12f4-4c6e-b4aa-531a76e27d04\", \"anomaly_model.tflite\", 91920)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the Keras model\n",
        "files.download('anomaly_model.keras')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "m1abtxUGcObo",
        "outputId": "6f2d5b13-5aa3-4a38-b276-0434444d03a1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e278105a-8d15-4d28-b331-a4eab4f3d59d\", \"anomaly_model.keras\", 306025)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}