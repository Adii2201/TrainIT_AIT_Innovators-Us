# -*- coding: utf-8 -*-
"""Untitled37.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_ZPwxUP_eZdCqyo8YftQp7bu7nQPien7
"""

!pip install numpy pandas matplotlib scikit-learn tensorflow

import pandas as pd

data = pd.read_csv('/content/data.csv', encoding='latin1')  # or ISO-8859-1
print(data.columns)  # Show available column names

print("Original dataset shape:", data.shape)
data = data.dropna()
print("After dropping NaN:", data.shape)  # Should not be (0, X)

import pandas as pd

data = pd.read_csv('/content/data.csv', encoding='latin1', low_memory=False)
print(data.head())  # Show first 5 rows
print("Dataset shape:", data.shape)

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Load dataset with correct encoding
data = pd.read_csv('/content/data.csv', encoding='latin1', low_memory=False)

# Convert numeric columns safely
num_cols = ['so2', 'no2', 'rspm', 'spm', 'pm2_5']
for col in num_cols:
    data[col] = pd.to_numeric(data[col], errors='coerce')  # Convert to numbers

# Fill missing values using the median of each column
for col in num_cols:
    data[col] = data[col].fillna(data[col].median())

# Define anomaly labels (Top 5% of PM2.5 as anomalies)
threshold = data['pm2_5'].quantile(0.95)
data['target'] = (data['pm2_5'] > threshold).astype(int)

# Select Features (Dropping non-relevant columns)
X = data[num_cols]  # Only numeric features
y = data['target']

# Normalize data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Confirm shape
print(f"Train set: {X_train.shape}, Test set: {X_test.shape}")

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Define Autoencoder Model
model = keras.Sequential([
    layers.Input(shape=(X_train.shape[1],)),
    layers.Dense(128, activation='relu'),
    layers.Dense(64, activation='relu'),
    layers.Dense(32, activation='relu'),  # Bottleneck (compressed representation)
    layers.Dense(64, activation='relu'),
    layers.Dense(128, activation='relu'),
    layers.Dense(X_train.shape[1], activation='sigmoid')  # Output same shape as input
])

model.compile(optimizer='adam', loss='mse')

# Train the model (unsupervised training)
history = model.fit(X_train, X_train, epochs=50, batch_size=32, validation_data=(X_test, X_test))

import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Predict reconstruction error
train_pred = model.predict(X_train)
train_mse = np.mean(np.power(X_train - train_pred, 2), axis=1)

test_pred = model.predict(X_test)
test_mse = np.mean(np.power(X_test - test_pred, 2), axis=1)

# Set anomaly detection threshold (95th percentile)
threshold = np.percentile(train_mse, 95)

# Classify anomalies
y_test_pred = (test_mse > threshold).astype(int)

# Evaluate model
accuracy = accuracy_score(y_test, y_test_pred)
precision = precision_score(y_test, y_test_pred)
recall = recall_score(y_test, y_test_pred)
f1 = f1_score(y_test, y_test_pred)

print(f"Model Performance:\nAccuracy: {accuracy}\nPrecision: {precision}\nRecall: {recall}\nF1-score: {f1}")

import joblib

import keras.saving
keras.saving.save_model(model, 'anomaly_model.keras')
joblib.dump(scaler, 'scaler.pkl')

# Generate performance report
report = f"""
Anomaly Detection Model Performance:
------------------------------------
Accuracy: {accuracy}
Precision: {precision}
Recall: {recall}
F1-score: {f1}
"""

with open("report.txt", "w") as file:
    file.write(report)

print("✅ Model saved & report generated!")

from tensorflow import keras

# Load the saved model
model = keras.models.load_model('anomaly_model.keras')

# Use it for predictions
predictions = model.predict(X_test)

from google.colab import files

# List of files to download
files_to_download = ['anomaly_model.keras', 'scaler.pkl', 'report.txt']

# Download each file
for file in files_to_download:
    files.download(file)

import tensorflow as tf

# Load your trained model
model = tf.keras.models.load_model('anomaly_model.keras')

# Convert the model to TensorFlow Lite format
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Save the .tflite model
with open("anomaly_model.tflite", "wb") as f:
    f.write(tflite_model)

print("✅ Model converted to TensorFlow Lite format.")

from google.colab import files
files.download('anomaly_model.tflite')  # Download the TensorFlow Lite model

from google.colab import files

# Download the Keras model
files.download('anomaly_model.keras')